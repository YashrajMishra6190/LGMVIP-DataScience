{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08a48dc7-a5ee-42ac-a155-0174e35ab375",
   "metadata": {},
   "source": [
    "# Handwritten Equation Solver using CNN: \n",
    "----\n",
    "About: Mathematical Equation Solver using character and Symbol recognition using Image Processing and CNN. \n",
    "\n",
    "- `Dataset Link:` https://www.kaggle.com/datasets/xainano/handwrittenmathsymbols\n",
    "\n",
    "I had faced some of the issue while importing some of the libraries in the newer versions of the Keras and Tensorflow there are some of the changes like, (--> changed to)\n",
    "- `from keras.utils import np_utils` --> `from keras import utils`\n",
    "- `from keras.np_utils import to_categorical` --> `-   from keras.utils import to_categorical`\n",
    "- Also there are no such module present as K.set_image_dim_odering('th'), which are changed to\n",
    "- this should read:\n",
    "- `K.set_image_dim_ordering('tf')` --> `K.set_image_data_format('channels_last')`\n",
    "\n",
    "- `K.set_image_dim_ordering('th') --> `K.set_image_data_format('channels_first')`\n",
    "\n",
    "- `K.image_dim_ordering() == 'tf'` --> `K.image_data_format() == 'channels_last'`\n",
    "\n",
    "- `K.image_dim_ordering() == 'th'`--> `K.image_data_format() == 'channels_first'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aab42ec-9aec-4561-8925-3bbfe6137aeb",
   "metadata": {},
   "source": [
    "# Steps: \r\n",
    "---\r\n",
    "\r\n",
    "1. Data Extraction\r\n",
    "2. Training and Building Model\r\n",
    "3. CNN Testing  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0406ca35-ff73-4c08-a96e-a6d668bd09a6",
   "metadata": {},
   "source": [
    "ing  annels_first'`st' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d109af3c-7c13-45be-b6ff-4fd5b029c1db",
   "metadata": {},
   "source": [
    "# Import Required Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "716cb9e3-34ce-4d34-99ba-0169a1734e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Training and Testing Dataset \n",
    "np.random.seed(1212)\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten, Conv2D, MaxPooling2D\n",
    "# from keras.layers.convolutional import Conv2D\n",
    "# from keras.layers.convolutional import MaxPooling2D\n",
    "# from keras.utils import np_utils\n",
    "from keras import utils\n",
    "from keras import backend as K\n",
    "#K.set_image_dim_ordering('th')\n",
    "K.set_image_data_format('channels_first')\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3644b43-dbfa-4692-9851-d0cbe5d69f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: keras\n",
      "Version: 3.2.1\n",
      "Summary: Multi-backend Keras.\n",
      "Home-page: https://github.com/keras-team/keras\n",
      "Author: Keras team\n",
      "Author-email: keras-users@googlegroups.com\n",
      "License: Apache License 2.0\n",
      "Location: C:\\Users\\YASHRAJ MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\n",
      "Requires: absl-py, h5py, ml-dtypes, namex, numpy, optree, rich\n",
      "Required-by: tensorflow-intel\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a314e60-6edd-49bd-bb4f-cee44b67166d",
   "metadata": {},
   "source": [
    "# 1. Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3836b8f2-14bb-40cb-8dc1-a5c6e92b7ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    train_data=[]\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename),cv2.IMREAD_GRAYSCALE)\n",
    "        img=~img\n",
    "        if img is not None:\n",
    "            ret,thresh=cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "            ctrs,ret=cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "            cnt=sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "            w=int(28)\n",
    "            h=int(28)\n",
    "            maxi=0\n",
    "            for c in cnt:\n",
    "                x,y,w,h=cv2.boundingRect(c)\n",
    "                maxi=max(w*h,maxi)\n",
    "                if maxi==w*h:\n",
    "                    x_max=x\n",
    "                    y_max=y\n",
    "                    w_max=w\n",
    "                    h_max=h\n",
    "            im_crop= thresh[y_max:y_max+h_max+10, x_max:x_max+w_max+10]\n",
    "            im_resize = cv2.resize(im_crop,(28,28))\n",
    "            im_resize=np.reshape(im_resize,(784,1))\n",
    "            train_data.append(im_resize)\n",
    "    return train_data\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9a82c53-29d0-451d-a204-0ed49c10869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9245de-71d2-4bd5-92d1-4a8e437f0981",
   "metadata": {},
   "source": [
    "## Assigning Folder Values: \n",
    "----\n",
    "In the data.rar file there are more of folder containing different symobols (operators) and numeric digit from 0 to 9 \n",
    "so, Assigining values: to operators and numeric nos.\n",
    "\n",
    "- 1 --> 1\n",
    "- 2 --> 2\n",
    "- 3 --> 3\n",
    "- 4 --> 4\n",
    "- 5 --> 5\n",
    "- 6 --> 6\n",
    "- 7 --> 7\n",
    "- 8 --> 8\n",
    "- 9 --> 9\n",
    "- '-' --> 10\n",
    "- '+' --> 11\n",
    "- 'times'/'*' --> 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05e0bfce-0edb-4359-95ca-88af9729116e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33997\n"
     ]
    }
   ],
   "source": [
    "data=load_images_from_folder('-')\n",
    "len(data)\n",
    "for i in range(0,len(data)):\n",
    "    data[i]=np.append(data[i],['10'])\n",
    "    \n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0154a377-7d26-4255-b2b4-2d96199c7fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59109\n"
     ]
    }
   ],
   "source": [
    "data11=load_images_from_folder('+')\n",
    "\n",
    "for i in range(0,len(data11)):\n",
    "    data11[i]=np.append(data11[i],['11'])\n",
    "data=np.concatenate((data,data11))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4d3f95e-7115-4c95-9bf5-bbd3f111c3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64574\n"
     ]
    }
   ],
   "source": [
    "data0=load_images_from_folder('0')\n",
    "for i in range(0,len(data0)):\n",
    "    data0[i]=np.append(data0[i],['0'])\n",
    "data=np.concatenate((data,data0))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ffb511b-aca2-4e95-b4a9-885f5fc5209a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91094\n"
     ]
    }
   ],
   "source": [
    "data1=load_images_from_folder('1')\n",
    "\n",
    "for i in range(0,len(data1)):\n",
    "    data1[i]=np.append(data1[i],['1'])\n",
    "data=np.concatenate((data,data1))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0303d88-c75f-4fb4-8a22-a7381b8eb282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117235\n"
     ]
    }
   ],
   "source": [
    "data2=load_images_from_folder('2')\n",
    "\n",
    "for i in range(0,len(data2)):\n",
    "    data2[i]=np.append(data2[i],['2'])\n",
    "data=np.concatenate((data,data2))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b9f42e9-5489-4c41-8d8c-3a90e70527c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128144\n"
     ]
    }
   ],
   "source": [
    "data3=load_images_from_folder('3')\n",
    "\n",
    "for i in range(0,len(data3)):\n",
    "    data3[i]=np.append(data3[i],['3'])\n",
    "data=np.concatenate((data,data3))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31b48b8b-47ef-4a77-b3fe-e2600578cd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135540\n"
     ]
    }
   ],
   "source": [
    "data4=load_images_from_folder('4')\n",
    "\n",
    "for i in range(0,len(data4)):\n",
    "    data4[i]=np.append(data4[i],['4'])\n",
    "data=np.concatenate((data,data4))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d971bc9-5adc-4a49-bfe2-4630d0f09ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139085\n"
     ]
    }
   ],
   "source": [
    "data5=load_images_from_folder('5')\n",
    "\n",
    "for i in range(0,len(data5)):\n",
    "    data5[i]=np.append(data5[i],['5'])\n",
    "data=np.concatenate((data,data5))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e87e6658-13ef-4bd0-ad6e-14d0e9b9b468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142203\n"
     ]
    }
   ],
   "source": [
    "data6=load_images_from_folder('6')\n",
    "\n",
    "for i in range(0,len(data6)):\n",
    "    data6[i]=np.append(data6[i],['6'])\n",
    "data=np.concatenate((data,data6))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a946bbdd-d6b0-4a16-a774-89b94e3fead2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145112\n"
     ]
    }
   ],
   "source": [
    "data7=load_images_from_folder('7')\n",
    "\n",
    "for i in range(0,len(data7)):\n",
    "    data7[i]=np.append(data7[i],['7'])\n",
    "data=np.concatenate((data,data7))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fff7b3f3-64f4-43b1-8d00-1048c13a1882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148180\n"
     ]
    }
   ],
   "source": [
    "data8=load_images_from_folder('8')\n",
    "\n",
    "for i in range(0,len(data8)):\n",
    "    data8[i]=np.append(data8[i],['8'])\n",
    "data=np.concatenate((data,data8))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fbdbc6cf-7ec0-4c15-93ec-74c181b8ee71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151917\n"
     ]
    }
   ],
   "source": [
    "data9=load_images_from_folder('9')\n",
    "\n",
    "for i in range(0,len(data9)):\n",
    "    data9[i]=np.append(data9[i],['9'])\n",
    "data=np.concatenate((data,data9))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff080acf-1770-418f-81dd-3639a2e96d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155168\n"
     ]
    }
   ],
   "source": [
    "data12=load_images_from_folder('times')\n",
    "\n",
    "for i in range(0,len(data12)):\n",
    "    data12[i]=np.append(data12[i],['12'])\n",
    "data=np.concatenate((data,data12))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38353171-ccf0-45e2-af26-0368afaded29",
   "metadata": {},
   "source": [
    "## Saving Extracted File as CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a3a3200-d8c8-4553-ab51-bc75330d5a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data,index=None)\n",
    "df.to_csv('train_final.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbaf7ad6-d769-4f41-bb5c-f51e918544c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('train_final.csv',index_col=False)\n",
    "labels=df_train[['784']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe557c6-87bc-4370-a066-d7bbd28a615b",
   "metadata": {},
   "source": [
    "# 2. Training and Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94b68003-c7b5-4ebd-b41e-34ad6f65383e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  774  775  776  777  \\\n",
       "0  255  255  255  255  255  255  255  255  255  255  ...    0    0    0    0   \n",
       "1  255  255  255  255  255  255  255  255  255  255  ...    0    0    0    0   \n",
       "2  255  255  255  255  255  255  255  255  255  255  ...    0    0    0    0   \n",
       "3  255  255  255  255  255  255  255  255  255  255  ...    0    0    0    0   \n",
       "4  255  255  255  255  255  255  255  255  255  255  ...    0    0    0    0   \n",
       "\n",
       "   778  779  780  781  782  783  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.drop(df_train.columns[[784]],axis=1,inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "37bf04d8-55b5-4779-b18e-61324fc5948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1fe17a86-7ac5-4f10-8ae1-3f3f8dd7ccf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "cat=to_categorical(labels,num_classes=13)\n",
    "print(cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ede7311-4d61-440d-a76a-14db2b8be710",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in range(155168):\n",
    "    l.append(np.array(df_train[i:i+1]).reshape(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a2974cea-a3bd-4080-9691-305c93380c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "232305c9-b633-4d89-922e-b768885081b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(30, (5, 5), input_shape=(1 , 28, 28), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(13, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c951f69-a39a-403c-95d6-af13d21e1f40",
   "metadata": {},
   "source": [
    "## Fitting Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c6db622a-eb31-42b9-8403-86ecacff9609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 375ms/step - accuracy: 0.7328 - loss: 1.4447\n",
      "Epoch 2/10\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 366ms/step - accuracy: 0.9626 - loss: 0.1285\n",
      "Epoch 3/10\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 379ms/step - accuracy: 0.9778 - loss: 0.0784\n",
      "Epoch 4/10\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 369ms/step - accuracy: 0.9838 - loss: 0.0565\n",
      "Epoch 5/10\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 369ms/step - accuracy: 0.9866 - loss: 0.0471\n",
      "Epoch 6/10\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 369ms/step - accuracy: 0.9894 - loss: 0.0369\n",
      "Epoch 7/10\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 370ms/step - accuracy: 0.9905 - loss: 0.0324\n",
      "Epoch 8/10\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 370ms/step - accuracy: 0.9916 - loss: 0.0281\n",
      "Epoch 9/10\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 370ms/step - accuracy: 0.9923 - loss: 0.0253\n",
      "Epoch 10/10\n",
      "\u001b[1m776/776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 370ms/step - accuracy: 0.9929 - loss: 0.0240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1cbbfd22390>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(l), cat, epochs=10, batch_size=200,shuffle=True,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7374dc59-f370-445b-a10f-39ae2be57bcc",
   "metadata": {},
   "source": [
    "## Saving model as 'model_final.weights.h5' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70ab79a0-ec7b-4250-85a4-7f0d72f81488",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model_final.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_final.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "38af8606-12e6-4904-9917-cc4c3e84146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('model_final.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_final.weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df8f7f-2252-4e6b-9ab4-9dbb175f8ff8",
   "metadata": {},
   "source": [
    "# Model Testing Using CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "451e3e7c-5378-4d37-866d-fc0828a57694",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test.jpeg',cv2.IMREAD_GRAYSCALE)\n",
    "#kernel = np.ones((3,3),np.uint8)\n",
    "cv2.imshow(\"wo\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#erosion = cv2.erode(img,kernel,iterations = 3)\n",
    "#dilation = cv2.dilate(img,kernel,iterations = 1)\n",
    "#img=dilation\n",
    "if img is not None:\n",
    "    #images.append(img)\n",
    "    img=~img\n",
    "    ret,thresh=cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "    ctrs,ret=cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnt=sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "    w=int(28)\n",
    "    h=int(28)\n",
    "    train_data=[]\n",
    "    #print(len(cnt))\n",
    "    rects=[]\n",
    "    for c in cnt :\n",
    "        x,y,w,h= cv2.boundingRect(c)\n",
    "        rect=[x,y,w,h]\n",
    "        rects.append(rect)\n",
    "    #print(rects)\n",
    "    bool_rect=[]\n",
    "    for r in rects:\n",
    "        l=[]\n",
    "        for rec in rects:\n",
    "            flag=0\n",
    "            if rec!=r:\n",
    "                if r[0]<(rec[0]+rec[2]+10) and rec[0]<(r[0]+r[2]+10) and r[1]<(rec[1]+rec[3]+10) and rec[1]<(r[1]+r[3]+10):\n",
    "                    flag=1\n",
    "                l.append(flag)\n",
    "            if rec==r:\n",
    "                l.append(0)\n",
    "        bool_rect.append(l)\n",
    "    #print(bool_rect)\n",
    "    dump_rect=[]\n",
    "    for i in range(0,len(cnt)):\n",
    "        for j in range(0,len(cnt)):\n",
    "            if bool_rect[i][j]==1:\n",
    "                area1=rects[i][2]*rects[i][3]\n",
    "                area2=rects[j][2]*rects[j][3]\n",
    "                if(area1==min(area1,area2)):\n",
    "                    dump_rect.append(rects[i])\n",
    "    #print(len(dump_rect)) \n",
    "    final_rect=[i for i in rects if i not in dump_rect]\n",
    "    #print(final_rect)\n",
    "    for r in final_rect:\n",
    "        x=r[0]\n",
    "        y=r[1]\n",
    "        w=r[2]\n",
    "        h=r[3]\n",
    "        im_crop =thresh[y:y+h+10,x:x+w+10]\n",
    "        \n",
    "\n",
    "        im_resize = cv2.resize(im_crop,(28,28))\n",
    "        cv2.imshow(\"work\",im_resize)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        im_resize=np.reshape(im_resize,(1,28,28))\n",
    "        train_data.append(im_resize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3a29c4-9bd1-4d6d-840d-bf0e8f17fe8f",
   "metadata": {},
   "source": [
    "## Final Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0f6a2aae-5c47-4f49-a443-5ef26ec02fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "42+4\n"
     ]
    }
   ],
   "source": [
    "s=''\n",
    "for i in range(len(train_data)):\n",
    "    train_data[i]=np.array(train_data[i])\n",
    "    train_data[i]=train_data[i].reshape(1,1,28,28)\n",
    "    #result=loaded_model.predict_classes(train_data[i])\n",
    "    result=np.argmax(loaded_model.predict(train_data[i]), axis=-1)\n",
    "    if(result[0]==10):\n",
    "        s=s+'-'\n",
    "    if(result[0]==11):\n",
    "        s=s+'+'\n",
    "    if(result[0]==12):\n",
    "        s=s+'*'\n",
    "    if(result[0]==0):\n",
    "        s=s+'0'\n",
    "    if(result[0]==1):\n",
    "        s=s+'1'\n",
    "    if(result[0]==2):\n",
    "        s=s+'2'\n",
    "    if(result[0]==3):\n",
    "        s=s+'3'\n",
    "    if(result[0]==4):\n",
    "        s=s+'4'\n",
    "    if(result[0]==5):\n",
    "        s=s+'5'\n",
    "    if(result[0]==6):\n",
    "        s=s+'6'\n",
    "    if(result[0]==7):\n",
    "        s=s+'7'\n",
    "    if(result[0]==8):\n",
    "        s=s+'8'\n",
    "    if(result[0]==9):\n",
    "        s=s+'9'\n",
    "    \n",
    "print(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fc40881e-9be6-48e2-8e43-abe01a8cc62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483abf6b-5b3f-4ed6-8433-b5050785eb00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
